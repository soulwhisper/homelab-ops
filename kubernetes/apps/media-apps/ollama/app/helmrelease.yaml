---
# yaml-language-server: $schema=https://kubernetes-schemas.noirprime.com/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &name ollama
spec:
  interval: 30m
  chartRef:
    kind: OCIRepository
    name: app-template
    namespace: gitops-system

  values:
    controllers:
      *name :
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          app:
            image:
              repository: mirror.gcr.io/ollama/ollama
              tag: 0.12.9
            env:
              OLLAMA_MODELS: "/models"
              OLLAMA_HOST: "0.0.0.0:11434"
              OLLAMA_FLASH_ATTENTION: "1"
              OLLAMA_MAX_LOADED_MODELS: "3"
              OLLAMA_KV_CACHE_TYPE: "q8_0"
              HTTPS_PROXY: "${HTTPS_PROXY}"
              NO_PROXY: "${NO_PROXY}"
            resources:
              requests:
                cpu: 20m
              limits:
                memory: 40Gi

    service:
      app:
        ports:
          http:
            port: 11434

    # : models
    # DeepSeek-R1-Distill-Qwen-7B-uncensored:latest - 15GB
    # gpt-oss:20b - 14GB
    # mistral:7b - 4.4GB

    persistence:
      app:
        existingClaim: *name
        globalMounts:
          - path: /root/.ollama
      shared:
        existingClaim: models
        globalMounts:
          - path: /models
